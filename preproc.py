"Preprocessing of the dataset"

import csv
import pandas as pd
import sys
import json
from random import random
from glob import glob
import os

def count_rows_csv(filename):
    if filename=='train':
        return 8921483
    if filename=='test':
        return 7853253
    count = -1
    with open(filename + '.csv', 'r') as fr:
        for row in fr:
            count+=1
    return count

def count_unique_values(filename = 'train.csv'):
    with open(filename, 'r') as fr:
        reader = csv.reader(fr)
        columns = next(reader)
        unique_values = {}
        for column in columns:
            if column == 'MachineIdentifier':
                continue
            unique_values[column] = {}
        for row in reader:
            for column, value in zip(columns, row):
                if column == 'MachineIdentifier':
                    continue
                unique_values[column][value] = unique_values[column][value]+1\
                    if value in unique_values[column] else 1

    with open('unique_values.json', 'w') as fw:
        fw.write(json.dumps(unique_values))


def split_csv(filename, chunk_size):
    with open(filename + '.csv', 'r') as fr:
        header = next(fr)
        def save_csv(df, i):
            fn = 'chunked/' + filename + str(i).zfill(5) + '_split' + '.csv'
            with open(fn, 'w') as fw:
                fw.write(header)
                for row in df:
                    fw.write(row)
        df = []
        i = 0
        for row in fr:
            if len(df) == chunk_size:
                save_csv(df, i)
                i+=1
                df = []
            df.append(row)
        save_csv(df, i)

def subset_csv(filename, N):
    row_count = count_rows_csv(filename)
    proba = float(N)/row_count
    with open(filename + '.csv', 'r') as fr:
        header = next(fr)
        df = []
        for row in fr:
            if random() < proba:
                df.append(row)
    with open(filename + '_split.csv', 'w') as fw:
        fw.write(header)
        for row in df:
            fw.write(row)

def preproc_csv(filename, postfix, cat_encoding):
    leave_intact_columns = ['MachineIdentifier', 'IsBeta', 'IsSxsPassiveMode',
        'HasTpm', 'AutoSampleOptIn', 'Census_HasOpticalDiskDrive',
        'Census_IsPortableOperatingSystem', 'Census_IsSecureBootEnabled',
        'Census_IsTouchEnabled', 'Census_IsPenCapable']

    if filename[:5] == 'train':
        leave_intact_columns.append('HasDetections')

    fill_05_columns = ['IsProtected', 'SMode', 'Firewall',
        'Census_IsFlightingInternal', 'Census_IsFlightsDisabled',
        'Census_ThresholdOptIn', 'Census_IsWIMBootEnabled',
        'Census_IsVirtualDevice', 'Census_IsAlwaysOnAlwaysConnectedCapable',
        'Wdft_IsGamer']

    fill_na_with_median_columns = [\
        'Census_InternalPrimaryDiagonalDisplaySizeInInches',
        'Census_InternalPrimaryDisplayResolutionHorizontal',
        'Census_InternalPrimaryDisplayResolutionVertical',
        'Census_InternalBatteryNumberOfCharges']

    fill_0_and_na_with_median_columns = [\
        'Census_PrimaryDiskTotalCapacity',
        'Census_SystemVolumeTotalCapacity',
        'Census_TotalPhysicalRAM']

    categorical_columns = ['Census_FlightRing',
        'ProductName', 'RtpStateBitfield',
        'AVProductsInstalled', 'AVProductsEnabled',
        'Platform', 'Processor', 'OsSuite', 
        'OsPlatformSubRelease', 'SkuEdition',
        'PuaMode', 'SmartScreen', 'UacLuaenable',
        'Census_MDC2FormFactor', 'Census_DeviceFamily',
        'Census_ProcessorManufacturerIdentifier',
        'Census_OSArchitecture', 'Census_OSBranch',
        'Census_OSEdition', 'Census_OSSkuName',
        'Census_OSInstallTypeName',
        'Census_OSWUAutoUpdateOptionsName',
        'Census_GenuineStateName',
        'Census_ActivationChannel',
        'Census_PrimaryDiskTypeName',
        'Census_ProcessorClass',
        'Census_ProcessorCoreCount',
        'OrganizationIdentifier',
        'Census_OSInstallLanguageIdentifier',
        'Wdft_RegionIdentifier',
        'OsBuild']

    leave_large_categorical_columns = [\
        'Census_OSBuildRevision',
        'DefaultBrowsersIdentifier',
        'AVProductStatesIdentifier',
        'CityIdentifier',
        'GeoNameIdentifier',
        'LocaleEnglishNameIdentifier',
        'IeVerIdentifier',
        'CountryIdentifier',
        'Census_ChassisTypeName',
        'Census_PowerPlatformRoleName',
        'Census_InternalBatteryType',
        'Census_OEMNameIdentifier',
        'Census_OEMModelIdentifier',
        'Census_ProcessorModelIdentifier',
        'Census_FirmwareManufacturerIdentifier',
        'Census_FirmwareVersionIdentifier',
        'Census_OSUILocaleIdentifier',
        'Census_OSBuildNumber']

    version_columns = ['OsVer', 'EngineVersion', 'AppVersion',
        'AvSigVersion', 'Census_OSVersion', 'OsBuildLab']

    usecols = leave_intact_columns + fill_05_columns \
        + fill_na_with_median_columns \
        + fill_0_and_na_with_median_columns \
        + categorical_columns \
        + leave_large_categorical_columns \
        + version_columns
    dtypes = {'Census_ChassisTypeName': str}
    for column in leave_intact_columns[1:] + fill_05_columns\
        + fill_na_with_median_columns + fill_0_and_na_with_median_columns:
        dtypes[column] = float

    with open('unique_values.json', 'r') as fr:
        unique_values = json.loads(fr.read())

    df = pd.read_csv(filename+postfix+'.csv', usecols=usecols,
        dtype=dtypes)

    for column in fill_0_and_na_with_median_columns:
        df[column].replace(0, None, inplace=True)

    for column in fill_05_columns +\
    fill_0_and_na_with_median_columns + fill_na_with_median_columns:
        df[column + '_isnan'] = df[column]
        df.loc[~df[column + '_isnan'].isnull(), column + '_isnan'] = 0
        df.loc[ df[column + '_isnan'].isnull(), column + '_isnan'] = 1

    df[fill_05_columns] = df[fill_05_columns].fillna(0.5)

    for column in fill_0_and_na_with_median_columns + fill_na_with_median_columns:
        df[column].fillna(df[column].median(), inplace=True)

    for column in version_columns:
        split_values = [[], [], [], []]
        for i in range(len(split_values)):
            unique_values[column+str(i)] = {}
        for value in df[column]:
            split_value = value.split('.') if isinstance(value, str) else [-1, -1, None, None]
            for i in range(len(split_values)):
                current_column = column + str(i)
                current_value = split_value[i]\
                    if (column == 'OsBuildLab') and (i>=2)\
                    else int(split_value[i]) 
                split_values[i].append(current_value)
                unique_values[current_column][current_value] = unique_values[current_column][current_value]+1\
                    if current_value in unique_values[current_column] else 1
        for i in range(len(split_values)):
            current_column = column + str(i)
            df[current_column] = split_values[i]
            if (column == 'OsBuildLab') and (i>=2):
                categorical_columns.append(current_column)

    df.drop(version_columns, axis=1, inplace=True)

    if cat_encoding in ['_onehot', '_onehot_na']:
        for column in leave_large_categorical_columns:
            frequencies = [(value, key) for key, value in unique_values[column].items()]
            frequencies.sort(reverse=True)
            values_to_leave = [value for freq, value in frequencies[:30] if freq>10]
            df[column].where(df[column].isin(values_to_leave), other='HEN3BECTHO', inplace = True)

    if cat_encoding=='_onehot':
        df = pd.get_dummies(df, columns=categorical_columns+leave_large_categorical_columns, dummy_na=False)
    elif cat_encoding=='_onehot_na':
        df = pd.get_dummies(df, columns=categorical_columns+leave_large_categorical_columns, dummy_na=True)
    elif cat_encoding=='_label':
        for column in categorical_columns+leave_large_categorical_columns:
            df[column] = df[column].astype('category').cat.codes
    df.to_csv(filename+cat_encoding+'.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)


def pipeline(what, cat_encoding, split_anew):
    if what == []:
        what = ['train', 'test']
    if 'train' in what:
        if split_anew:
            print('Subsetting train...')
            subset_csv('train', N=300000)
        print('Preprocessing train subset...')
        preproc_csv('train', postfix='_split', cat_encoding=cat_encoding)

    if 'test' in what:
        if split_anew:
            to_delete_filenames = glob('chunked/test*.csv')
            print('Cleaning up...')
            for filename in to_delete_filenames:
                os.remove(filename)
            print('Splitting test...')
            split_csv('test', chunk_size=100000)
        test_filenames = glob('chunked/test*_split.csv')
        test_filenames.sort()
        for filename in test_filenames:
            print('Preprocessing %s' % filename)
            preproc_csv(filename[:-10], postfix='_split', cat_encoding=cat_encoding)


if __name__=='__main__':
    what = []
    split_anew = False
    if len(sys.argv)>=2:
        for s in sys.argv[1:]:
            if s[0] == '_':
                cat_encoding = s
            if s in ['train', 'test']:
                what.append(s)
            if s == 'split_anew':
                split_anew = True
    print(what, cat_encoding)
    pipeline(what, cat_encoding, split_anew=split_anew)
